{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Review\n",
        "\n",
        "The 5 biggest LLM providers are OpenAI, Google, Anthropic, Meta, and Mistral. There are many ways to compare these models. Cost, quality, speed, context length. Open vs Closed models. In this notebook, we will compare the outputs of these models.\n",
        "\n",
        "## Setup\n",
        "\n",
        "We will start by installing the necessary libraries and importing them. Ensure you have access to the APIs of the respective models.\n"
      ],
      "metadata": {
        "id": "RNdQjJKyWOBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain langchain-google-genai langchain-anthropic langchain-openai pandas google-generativeai IPython singlestoredb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wSXwHBbWUGi",
        "outputId": "dd46b5c3-1289-445f-f1ce-65f43b31a52e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.10/dist-packages (0.1.11)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Collecting singlestoredb\n",
            "  Downloading singlestoredb-1.3.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.3/373.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.57)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: anthropic<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.25.9)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.7.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: PyJWT in /usr/lib/python3/dist-packages (from singlestoredb) (2.3.0)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (from singlestoredb) (1.2.1)\n",
            "Collecting parsimonious (from singlestoredb)\n",
            "  Downloading parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlparams (from singlestoredb)\n",
            "  Downloading sqlparams-6.0.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from singlestoredb) (0.43.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from singlestoredb) (2.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.23.0->langchain-anthropic) (0.19.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build->singlestoredb) (1.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<1,>=0.23.0->langchain-anthropic) (0.20.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.23.0->langchain-anthropic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.23.0->langchain-anthropic) (2023.6.0)\n",
            "Installing collected packages: sqlparams, parsimonious, singlestoredb\n",
            "Successfully installed parsimonious-0.10.0 singlestoredb-1.3.0 sqlparams-6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"Your Key\"\n",
        "google_api_key = \"Your Key\"\n",
        "anthropic_api_key = \"Your Key\""
      ],
      "metadata": {
        "id": "dnYkZIg7x8p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "claude = ChatAnthropic(temperature=0, model_name=\"claude-3-opus-20240229\", api_key=anthropic_api_key)\n",
        "\n",
        "cluade.invoke([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"Explain neural networks in 2 sentences.\"),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MVxvCAgXs5j",
        "outputId": "d0300d26-c430-44f3-b41e-c48ba30019b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Here is the translation of \"I love programming\" in French:\\n\\nJ\\'adore la programmation.', response_metadata={'id': 'msg_014Kr4FkrY339WqmGK394Zt6', 'model': 'claude-3-opus-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 44, 'output_tokens': 25}}, id='run-23d9f030-2be8-4634-a39e-320200899930-0')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=openai_api_key)\n",
        "\n",
        "gpt.invoke([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"Explain neural networks in 2 sentences.\"),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GBRxIOho4rt",
        "outputId": "7765b1e1-c230-4ef3-90fb-bf37b50d6413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Neural networks are computational models inspired by the human brain, consisting of interconnected layers of nodes (neurons) that process and learn from data through weighted connections. They are widely used in machine learning for tasks such as image recognition, natural language processing, and predictive analytics.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 24, 'total_tokens': 78}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_729ea513f7', 'finish_reason': 'stop', 'logprobs': None}, id='run-2c53353f-9e10-42a8-87d5-8acfe6089780-0')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0, google_api_key=google_api_key)\n",
        "\n",
        "gemini.invoke([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"Explain neural networks in 2 sentences.\"),\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjhMrbDoXtup",
        "outputId": "191f2167-91ad-4cf3-d70e-7ff47636329b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Neural networks are computational models inspired by the human brain, consisting of interconnected nodes (neurons) that process information and learn patterns through training on data. They are used in various applications, including image recognition, natural language processing, and decision-making.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-0d40e972-b259-4518-a8e0-63cc43fe2a93-0')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "gpt = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=openai_api_key)\n",
        "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0, google_api_key=google_api_key)\n",
        "claude = ChatAnthropic(temperature=0, model_name=\"claude-3-opus-20240229\", api_key=anthropic_api_key)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Example invocation:\n",
        "gemini.invoke([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"Explain neural networks in 2 sentences.\"),\n",
        "]).content\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "g8lE4KzpzL9D",
        "outputId": "8a1a8f8c-12e5-45b9-f765-e577d7aa94b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nExample invocation:\\ngemini.invoke([\\n    (\"system\", \"You are a helpful assistant\"),\\n    (\"human\", \"Explain neural networks in 2 sentences.\"),\\n]).content\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions and Answers\n",
        "\n",
        "We will use a set of predefined basic and complex STEM questions. The correct answers will be stored for evaluation.\n"
      ],
      "metadata": {
        "id": "ApEgdYyD2ySs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define questions and correct answers\n",
        "questions = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"Explain the theory of relativity in two sentences.\",\n",
        "    \"What is the derivative of x^2?\",\n",
        "    \"Translate 'The quick brown fox jumps over the lazy dog' to French.\",\n",
        "    \"Solve the equation: 2x + 3 = 7.\"\n",
        "]\n",
        "\n",
        "correct_answers = [\n",
        "    \"Paris\",\n",
        "    \"The theory of relativity, developed by Albert Einstein, states that the laws of physics are the same for all non-accelerating observers and that the speed of light in a vacuum is constant regardless of the speed at which an observer travels. This theory revolutionized our understanding of space, time, and gravity.\",\n",
        "    \"2x\",\n",
        "    \"Le rapide renard brun saute par-dessus le chien paresseux.\",\n",
        "    \"x = 2\"\n",
        "]\n",
        "\n",
        "# Create a DataFrame to store questions and correct answers\n",
        "qa_df = pd.DataFrame({\n",
        "    'Question': questions,\n",
        "    'Correct Answer': correct_answers\n",
        "})\n"
      ],
      "metadata": {
        "id": "NDAX6oac0QXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Model Outputs\n",
        "\n",
        "We will generate responses from each model for the predefined questions.\n"
      ],
      "metadata": {
        "id": "odL6Cw3-3A-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "gpt = ChatOpenAI(model=\"gpt-4o\", temperature=0, api_key=openai_api_key)\n",
        "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0, google_api_key=google_api_key)\n",
        "claude = ChatAnthropic(temperature=0, model_name=\"claude-3-opus-20240229\", api_key=anthropic_api_key)\n",
        "\n",
        "# Generate responses for each question using GPT-4\n",
        "gpt_responses = []\n",
        "for question in questions:\n",
        "    try:\n",
        "        response = gpt.invoke([(\"system\", \"You are a helpful assistant\"), (\"human\", question)])\n",
        "        gpt_responses.append(response.content)\n",
        "    except Exception as e:\n",
        "        gpt_responses.append(f\"Error: {str(e)}\")\n",
        "\n",
        "qa_df['GPT-4 Response'] = gpt_responses\n",
        "\n",
        "# Generate responses for each question using Google Gemini\n",
        "gemini_responses = []\n",
        "for question in questions:\n",
        "    try:\n",
        "        response = gemini.invoke([(\"system\", \"You are a helpful assistant\"), (\"human\", question)])\n",
        "        gemini_responses.append(response.content)\n",
        "    except Exception as e:\n",
        "        gemini_responses.append(f\"Error: {str(e)}\")\n",
        "\n",
        "qa_df['Gemini Response'] = gemini_responses\n",
        "\n",
        "# Generate responses for each question using Claude\n",
        "claude_responses = []\n",
        "for question in questions:\n",
        "    try:\n",
        "        response = claude.invoke([(\"system\", \"You are a helpful assistant\"), (\"human\", question)])\n",
        "        claude_responses.append(response.content)\n",
        "    except Exception as e:\n",
        "        claude_responses.append(f\"Error: {str(e)}\")\n",
        "\n",
        "qa_df['Claude Response'] = claude_responses\n",
        "\n",
        "qa_df.to_csv('model_responses.csv', index=False)\n",
        "print(\"Responses saved to model_responses.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDMZrgyw3Bkl",
        "outputId": "a3eb6893-75a0-417b-8176-8f599db75134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Question  \\\n",
            "0                     What is the capital of France?   \n",
            "1  Explain the theory of relativity in two senten...   \n",
            "2                     What is the derivative of x^2?   \n",
            "3  Translate 'The quick brown fox jumps over the ...   \n",
            "4                    Solve the equation: 2x + 3 = 7.   \n",
            "\n",
            "                                      Correct Answer  \\\n",
            "0                                              Paris   \n",
            "1  The theory of relativity, developed by Albert ...   \n",
            "2                                                 2x   \n",
            "3  Le rapide renard brun saute par-dessus le chie...   \n",
            "4                                              x = 2   \n",
            "\n",
            "                                      GPT-4 Response  \\\n",
            "0                    The capital of France is Paris.   \n",
            "1  The theory of relativity, developed by Albert ...   \n",
            "2  The derivative of \\( x^2 \\) with respect to \\(...   \n",
            "3  The translation of 'The quick brown fox jumps ...   \n",
            "4  To solve the equation \\(2x + 3 = 7\\), follow t...   \n",
            "\n",
            "                                     Gemini Response  \\\n",
            "0                                              Paris   \n",
            "1  Error: Invalid argument provided to Gemini: 40...   \n",
            "2  Error: Invalid argument provided to Gemini: 40...   \n",
            "3  Error: Invalid argument provided to Gemini: 40...   \n",
            "4  Error: Invalid argument provided to Gemini: 40...   \n",
            "\n",
            "                                     Claude Response  \n",
            "0  Error: Error code: 429 - {'type': 'error', 'er...  \n",
            "1  Error: Error code: 429 - {'type': 'error', 'er...  \n",
            "2  The derivative of x^2 (squared) is 2x.\\n\\nTo e...  \n",
            "3  Here is the translation of that sentence into ...  \n",
            "4  Great! Let's solve the equation 2x + 3 = 7 ste...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Multimodal Capabilities\n",
        "\n",
        "Whats in this image: https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
      ],
      "metadata": {
        "id": "hov5L_R49iDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
        "        {\n",
        "          \"type\": \"image_url\",\n",
        "          \"image_url\": {\n",
        "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
        "          },\n",
        "        },\n",
        "      ],\n",
        "    }\n",
        "  ],\n",
        "  max_tokens=300,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "As9wIg2258RV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "img = PIL.Image.open('img.jpeg')\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro-vision')\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img], stream=True)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-cFJk8-4qm",
        "outputId": "a7776062-19f4-4970-c147-14694825163f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=False,\n",
            "    iterator=<_StreamingResponseIterator>,\n",
            "    result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': \" One of the best parts about meal prepping is being able to enjoy delicious, healthy meals on busy weeknights. This meal is a perfect example; it'\"}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}]}),\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrival Augmented Generation (RAG) vs Long Context Length"
      ],
      "metadata": {
        "id": "2TxQ5_HJ_pVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Long Context Length Test\n",
        "\n",
        "from IPython.display import Markdown\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0, google_api_key=google_api_key)\n",
        "\n",
        "with open('superbowl.txt', 'r') as file:\n",
        "    text_content = file.read()\n",
        "\n",
        "output = gemini.invoke([\n",
        "    (\"system\", \"Answer based on the users content (3 sentences max): Which celebrities were at the 2024 superbowl?\"),\n",
        "    (\"human\", text_content),\n",
        "])\n",
        "\n",
        "Markdown(output.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "nDjBCvBn_wre",
        "outputId": "4c1b24c5-5763-4cc5-9c03-b057b62f7211"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Super Bowl LVIII** was an American football game played to determine the champion of the National Football League (NFL) for the 2023 season. In a rematch of Super Bowl LIV from four years earlier, the American Football Conference (AFC) champion and defending Super Bowl champion Kansas City Chiefs defeated the National Football Conference (NFC) champion San Francisco 49ers 25–22 in overtime. The Chiefs became the first team to win back-to-back Super Bowls since the New England Patriots in 2004. The game was played on February 11, 2024, at Allegiant Stadium in Paradise, Nevada. This was the first Super Bowl to be held in the state of Nevada. It marked the third straight year that the Super Bowl had been played in the Western United States, following host cities Inglewood, California, in 2022 and Glendale, Arizona, in 2023.\n\nAs this was the Chiefs' fourth Super Bowl appearance and third win in five years, many have said this game established them as a dynasty. It was the second Super Bowl to be decided in overtime, the first being Super Bowl LI, seven years earlier. Chiefs quarterback Patrick Mahomes was named Super Bowl Most Valuable Player (MVP), completing 34 of 46 passes for 333 yards, two touchdowns, and one interception. Due to the seating capacity of Allegiant Stadium, the game's sellout attendance of 61,629 was the smallest crowd in Super Bowl history outside of Super Bowl LV, which was played during the COVID-19 pandemic.\n\nThe game was televised nationally by CBS, streamed on Paramount+, alternatively broadcast on youth-oriented sister network Nickelodeon, and televised on the Spanish-language network Univision. It was also the second simulcast in Super Bowl history since Super Bowl I. Super Bowl LVIII became the most watched program in American television history, with a total of 123.7 million average viewers across all platforms, which broke the average record of 115.1 million viewers set by the previous year's Super Bowl. The game saw the highest unduplicated total audience in history with more than 200 million viewers watching all or part of the game. It was the most-watched United States broadcast since the Apollo 11 moon landing, attributed to the Taylor Swift effect. The game lasted for 74 minutes and 57 seconds of game time, making it the longest Super Bowl in history."
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG Test\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.singlestoredb import SingleStoreDB\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import google.generativeai as gemini\n",
        "\n",
        "os.environ[\"SINGLESTOREDB_URL\"] = \"INSERT DB URL\"\n",
        "\n",
        "# Load and process documents\n",
        "loader = TextLoader(\"superbowl.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# Generate embeddings and create a document search database\n",
        "embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n",
        "docsearch = SingleStoreDB.from_documents(docs, embeddings, table_name=\"superbowl\")\n",
        "\n",
        "gemini.configure(api_key=google_api_key)\n",
        "\n",
        "# Chat loop\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_query = input(\"\\nYou: \")\n",
        "\n",
        "    # Check for exit command\n",
        "    if user_query.lower() in ['quit', 'exit']:\n",
        "        print(\"Exiting chatbot.\")\n",
        "        break\n",
        "\n",
        "    # Perform similarity search\n",
        "    docs = docsearch.similarity_search(user_query)\n",
        "    if docs:\n",
        "        context = docs[0].page_content\n",
        "\n",
        "        model = gemini.GenerativeModel('gemini-pro')\n",
        "\n",
        "        response = model.generate_content(user_query + context)\n",
        "\n",
        "        # Output the response\n",
        "        print(\"AI: \", end=\"\")\n",
        "        for chunk in response:\n",
        "            print(chunk.text)\n",
        "            print(\"_\" * 80)\n",
        "\n",
        "    else:\n",
        "        print(\"AI: Sorry, I couldn't find relevant information.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "mkymI-sHCBAS",
        "outputId": "0c9c6de6-4661-465b-c0b4-09e2ea502be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 6011, which is longer than the specified 2000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4792, which is longer than the specified 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You: Which celebrities were at 2024 superbowl?\n",
            "AI: According to the provided text, the following celebrities were at the 2024 Superbowl:\n",
            "\n",
            "- Beyoncé\n",
            "- Tony Hale\n",
            "- Arnold Schwarzenegger\n",
            "- Danny DeVito\n",
            "________________________________________________________________________________\n",
            "\n",
            "You: Thanks!\n",
            "AI: **Commercials:**\n",
            "\n",
            "* Featured AI-generated commercials for Microsoft Copilot, Etsy, and Google Pixel 8.\n",
            "* Political ad by a super PAC supporting Robert F. Kennedy Jr.\n",
            "* Criticism for the ad from Kennedy family members.\n",
            "* E-commerce retailer Temu aired commercials multiple times.\n",
            "* Beyoncé starred in a Verizon commercial teasing her upcoming music.\n",
            "\n",
            "**Streaming:**\n",
            "\n",
            "* Game streamed on Paramount+ in English.\n",
            "* Streamed on TelevisaUnivision's Vix in Spanish.\n",
            "* Streamed on the NFL+ app with a paid subscription.\n",
            "________________________________________________________________________________\n",
            "\n",
            "You: what else\n",
            "AI: **Aftermath:**\n",
            "\n",
            "* The Chiefs became the first team to win three Super Bowls in a five-season span since the New England Patriots (2001-2004).\n",
            "* The 49ers fired defensive coordinator Steve Wilks after one season due to poor defensive performances.\n",
            "* A victory parade was held in Kansas City, drawing a large crowd.\n",
            "* During the victory parade, a shooting occurred at Union Station, resulting in the death of one person and injuries to at least 21 others.\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}
