{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Review\n",
        "\n",
        "The 5 biggest LLM providers are OpenAI, Google, Anthropic, Meta, and Mistral. There are many ways to compare these models. Cost, quality, speed, context length. Open vs Closed models. In this notebook, we will compare the outputs of these models.\n",
        "\n",
        "## Setup\n",
        "\n",
        "We will start by installing the necessary libraries and importing them. Ensure you have access to the APIs of the respective models.\n"
      ],
      "metadata": {
        "id": "RNdQjJKyWOBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain langchain-google-genai langchain-anthropic"
      ],
      "metadata": {
        "id": "4wSXwHBbWUGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.llms import OpenAI, Google, Anthropic, Llama, Mistral\n",
        "\n",
        "# Set up your API keys here\n",
        "openai.api_key = \"your_openai_api_key\"\n",
        "google.api_key = \"your_google_api_key\"\n",
        "anthropic.api_key = \"your_anthropic_api_key\""
      ],
      "metadata": {
        "id": "4MVxvCAgXs5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input prompts\n",
        "inputs = [\n",
        "    \"Explain the theory of relativity.\",\n",
        "    \"Translate the following English sentence to French: 'The quick brown fox jumps over the lazy dog.'\",\n",
        "    \"Write a short story about a dragon and a knight.\",\n",
        "    \"What is the capital of France?\",\n",
        "    \"Generate a poem about nature.\"\n",
        "]\n",
        "\n",
        "# Generate outputs for each input using each model\n",
        "results = {}\n",
        "\n",
        "for prompt in inputs:\n",
        "    results[prompt] = {\n",
        "        \"GPT-4\": gpt4.generate(prompt),\n",
        "        \"Google Gemini\": gemini.generate(prompt),\n",
        "        \"Claude\": claude.generate(prompt),\n",
        "        \"Llama\": llama.generate(prompt),\n",
        "        \"Mistral\": mistral.generate(prompt)\n",
        "    }\n",
        "\n",
        "# Display the results\n",
        "for prompt, output in results.items():\n",
        "    print(f\"Input: {prompt}\\n\")\n",
        "    for model, response in output.items():\n",
        "        print(f\"{model}:\\n{response}\\n\")\n"
      ],
      "metadata": {
        "id": "DjhMrbDoXtup"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}